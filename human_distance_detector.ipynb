{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG4W0ynJr7mP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERGZLiujx6hW"
      },
      "source": [
        "\\## **A YOLO V-3 BASED HUMAN DISTANCE MONITORING SYSTEM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP9SqAN14AR8"
      },
      "source": [
        "\n",
        "```\n",
        "Hasan Tahsin Rafsan\n",
        "232137\n",
        "Section - A\n",
        "PMIT Program\n",
        "Admission Intake Summer 2023\n",
        "Institute of Information Technology\n",
        "Jahangirnagar University\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8wc0HxOFg_k"
      },
      "source": [
        "**1. Mount Google Drive for Google Colaboratory**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saWrVPV2OocW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U1Q9wYoGwut"
      },
      "source": [
        "**2. Check Python Version with Requirements**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDYyUBL9GxJF"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mefw6DVRlyuQ"
      },
      "source": [
        "**3. Creating The People Detection Function**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQgUUsQRhqoA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "MIN_DISTANCE = 50\n",
        "MIN_CONF = 0.3\n",
        "NMS_THRESH = 0.3\n",
        "\n",
        "# grab the dimensions of the frame based on height weight & initialize the list of results\n",
        "def detect_people(frame, net, ln, personIdx=0):\n",
        "    (H, W) = frame.shape[:2]\n",
        "    results = []\n",
        "    \"\"\"\n",
        "\t\t1. created a blob from the input frame\n",
        "\t\t2. perform a forward pass of the YOLO object detector\n",
        "\t\t3. giving us bounding boxes & associated probabilities\n",
        "\t\t\"\"\"\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    layerOutputs = net.forward(ln)\n",
        "\n",
        "    # initialize our lists of detected bounding boxes, centroids & confidences\n",
        "    boxes = []\n",
        "    centroids = []\n",
        "    confidences = []\n",
        "\n",
        "    # loop over each of the layer outputs\n",
        "    for output in layerOutputs:\n",
        "\n",
        "        # loop over each of the detections\n",
        "        for detection in output:\n",
        "\n",
        "            # extract the class ID & confidence (probability) of the current object detection\n",
        "            scores = detection[5:]\n",
        "            classID = np.argmax(scores)\n",
        "            confidence = scores[classID]\n",
        "\n",
        "            # filter detections by (a) ensuring that the object detected was a person & (b) that the minimum confidence is met\n",
        "            if classID == personIdx and confidence > MIN_CONF:\n",
        "\n",
        "                # YOLO returns the center (x,y) coordinates of bounding box with the boxes width & height\n",
        "                # scale the bounding box coordinates back relative to the size of the image\n",
        "                box = detection[0:4] * np.array([W, H, W, H])\n",
        "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                # use the center (x,y) coordiates to derive the top & left side of bounding box\n",
        "                x = int(centerX - (width / 2))\n",
        "                y = int(centerY - (height / 2))\n",
        "\n",
        "                # update our list of bounding box coordinates, centroids & confidences\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                centroids.append((centerX, centerY))\n",
        "                confidences.append(float(confidence))\n",
        "\n",
        "\t\t# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
        "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONF, NMS_THRESH)\n",
        "\n",
        "    # ensure at least one detection exists\n",
        "    if len(idxs) > 0:\n",
        "\n",
        "        # loop over the indexes we are keeping\n",
        "        for i in idxs.flatten():\n",
        "            # extract the bounding box coordinates\n",
        "            (x, y) = (boxes[i][0], boxes[i][1])\n",
        "            (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "            # update our results list to consist of the person prediction probability, bounding box coordinates & the centroid\n",
        "            r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
        "            results.append(r)\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Main Cofiguration File**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iRhXuJL_KPFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.spatial import distance as dist\n",
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "from urllib.request import urlretrieve\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Main location path inside Gdrive\n",
        "\n",
        "main_path = \"/content/drive/MyDrive/human-distance-detector\"\n",
        "base_link = \"https://gist.githubusercontent.com/htrafsan/9970463655660122974949a03369664a/raw\"\n",
        "\n",
        "\n",
        "# Load Required Files\n",
        "\n",
        "cocoPath = f\"{main_path}/yolo-coco/coco.names\"\n",
        "coco_cfg = f\"{main_path}/yolo-coco/yolov3.cfg\"\n",
        "coco_weights = f\"{main_path}/yolo-coco/yolov3.weights\"\n",
        "\n",
        "if os.path.isfile(cocoPath):\n",
        "    pass\n",
        "else:\n",
        "    print(\"[-] coco.names not found. Downloading..\")\n",
        "    urlretrieve(f\"{base_link}/coco.names\", cocoPath)\n",
        "\n",
        "LABELS = open(cocoPath).read().strip().split(\"\\n\")\n",
        "\n",
        "if os.path.isfile(coco_cfg):\n",
        "    pass\n",
        "else:\n",
        "    print(\"[-] coco.cfg not found. Downloading..\")\n",
        "    urlretrieve(f\"{base_link}/yolov3.cfg\", coco_cfg)\n",
        "if os.path.isfile(coco_weights):\n",
        "    pass\n",
        "else:\n",
        "    print(\"[!] Coco Weights Not Found.\")\n",
        "    print(f\"[!] Save inside {coco_weights}\")\n",
        "    os.sys.exit()\n",
        "\n",
        "# Create output if it does not exist\n",
        "output_dir = f\"{main_path}/output\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n"
      ],
      "metadata": {
        "id": "ONGsMDfKB_yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHLWA1WTmBlE"
      },
      "source": [
        "**5. Grab Frames from Video & Make Prediction Measuring Distances of Detected People**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H5EzEv31PQo"
      },
      "outputs": [],
      "source": [
        "# human_distance_detector.py\n",
        "\n",
        "# path to input video file\n",
        "input_name = f'{main_path}/my_input_cctv.mp4'\n",
        "\n",
        "# path to output video file\n",
        "output_name = f'{main_path}/output/train_{run_time}.avi'\n",
        "\n",
        "# path to output csv file\n",
        "csv_filename = f'{main_path}/output/train_{run_time}.csv'\n",
        "\n",
        "# show each frame on display (true, false)\n",
        "screen_display = True\n",
        "\n",
        "# data for the output frames\n",
        "frame_number = 0 # base frame num=0\n",
        "frame_results = []\n",
        "\n",
        "# Load Yolo Detector\n",
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net= cv2.dnn.readNetFromDarknet(coco_cfg, coco_weights)\n",
        "\n",
        "# determine only the Output layer names\n",
        "ln= net.getLayerNames()\n",
        "ln= [ln[i-1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# initialize the video stream & pointer to output video file\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "vs= cv2.VideoCapture(input_name if input_name else 0)\n",
        "writer= None\n",
        "\n",
        "\n",
        "# loop over the frames from the video stream\n",
        "while True:\n",
        "        # read the next frame from the file\n",
        "        (grabbed, frame) = vs.read()\n",
        "\n",
        "        # if the frame was not grabbed then we reached the end of the video\n",
        "        if not grabbed:\n",
        "                break\n",
        "\n",
        "        # resize the frame & detect only person in it\n",
        "        frame= imutils.resize(frame, width=700)\n",
        "        results= detect_people(frame, net, ln, personIdx=LABELS.index(\"person\"))\n",
        "\n",
        "        # initialize the set of indexes that violate the minimum safe distance\n",
        "        violate = set()\n",
        "\n",
        "        # ensure there is at least 2 people detections for computing pairwise distance maps\n",
        "        if len(results) >=2:\n",
        "\n",
        "                # extract all centroids from the results & compute the Euclidean distances between all pairs of centroids\n",
        "                centroids = np.array([r[2] for r in results])\n",
        "                D= dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
        "\n",
        "                # loop over the upper triangular of the distance matrix [i, j] i row j col\n",
        "                for i in range(0, D.shape[0]):\n",
        "                        for j in range(i+1, D.shape[1]):\n",
        "                                # check if the distance between any 2 centroid pairs is less than min dist or pixelese here\n",
        "                                if D[i,j] <MIN_DISTANCE:\n",
        "                                        # update our violation set with the indexes of the centroid pairs\n",
        "                                        violate.add(i)\n",
        "                                        violate.add(j)\n",
        "\n",
        "        # loop over the results\n",
        "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
        "                # extract the bounding box & centroid coordinates\n",
        "                (startX, startY, endX, endY) =bbox\n",
        "                (cX,cY) =centroid\n",
        "\n",
        "                # default annonation color is green\n",
        "                color= (0,255,0)\n",
        "\n",
        "                # if the index pair exists within the violation set then update the color RED\n",
        "                if i in violate:\n",
        "                        color= (0,0,255)\n",
        "\n",
        "                # draw a bounding box around the person & the centroid coordinates of the person\n",
        "                cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "                cv2.circle(frame, (cX, cY), 5, color, 1)\n",
        "\n",
        "\n",
        "        num_persons = len(results)\n",
        "        num_green = len(results) - len(violate)\n",
        "        num_red = len(violate)\n",
        "        frame_results.append([frame_number, num_persons, num_green, num_red])\n",
        "        frame_number += 1\n",
        "\n",
        "        text_green = \"Safe: {}\".format(num_green)\n",
        "        cv2.putText(frame, text_green, (10, frame.shape[0] - 55),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 255, 0), 3)\n",
        "\n",
        "        text_red = \"Violations: {}\".format(num_red)\n",
        "        cv2.putText(frame, text_red, (10, frame.shape[0] - 25),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
        "\n",
        "        # check to see if the output frame should be displayed to our screen\n",
        "        if screen_display:\n",
        "                cv2_imshow(frame)\n",
        "\n",
        "        # if an output video file path has been supplied & the video writer has not been initialized, do so now\n",
        "        if output_name != \"\" and writer is None:\n",
        "                # initialize video writer\n",
        "                fourcc= cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "                writer= cv2.VideoWriter(output_name, fourcc, 25, (frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "        # if the video writer is not None, write the frame to the output video file\n",
        "        if writer is not None:\n",
        "                writer.write(frame)\n",
        "\n",
        "\n",
        "# Save results in a csv file\n",
        "with open(csv_filename, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['frame', 'total_persons', 'safe', 'violations'])\n",
        "    writer.writerows(frame_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Os9E9a1MRh"
      },
      "source": [
        "**6. For B&W version**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMWw6mhGHj7S"
      },
      "outputs": [],
      "source": [
        "# human_distance_detector.py\n",
        "\n",
        "# path to input video file\n",
        "input_name = f'{main_path}/my_input_cctv_bw.mp4'\n",
        "\n",
        "# path to output video file\n",
        "output_name = f'{main_path}/output/bw_{run_time}.avi'\n",
        "\n",
        "# path to output csv file\n",
        "csv_filename = f'{main_path}/output/bw_{run_time}.csv'\n",
        "\n",
        "# show each frame on display (true, false)\n",
        "screen_display = True\n",
        "\n",
        "# data for the output frames\n",
        "frame_number = 0 # base frame num=0\n",
        "frame_results = []\n",
        "\n",
        "# Load Yolo Detector\n",
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net= cv2.dnn.readNetFromDarknet(coco_cfg, coco_weights)\n",
        "\n",
        "# determine only the Output layer names\n",
        "ln= net.getLayerNames()\n",
        "ln= [ln[i-1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# initialize the video stream & pointer to output video file\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "vs= cv2.VideoCapture(input_name if input_name else 0)\n",
        "writer= None\n",
        "\n",
        "\n",
        "# loop over the frames from the video stream\n",
        "while True:\n",
        "        # read the next frame from the file\n",
        "        (grabbed, frame) = vs.read()\n",
        "\n",
        "        # if the frame was not grabbed then we reached the end of the video\n",
        "        if not grabbed:\n",
        "                break\n",
        "\n",
        "        # resize the frame & detect only person in it\n",
        "        frame= imutils.resize(frame, width=700)\n",
        "        results= detect_people(frame, net, ln, personIdx=LABELS.index(\"person\"))\n",
        "\n",
        "        # initialize the set of indexes that violate the minimum safe distance\n",
        "        violate = set()\n",
        "\n",
        "        # ensure there is at least 2 people detections for computing pairwise distance maps\n",
        "        if len(results) >=2:\n",
        "\n",
        "                # extract all centroids from the results & compute the Euclidean distances between all pairs of centroids\n",
        "                centroids = np.array([r[2] for r in results])\n",
        "                D= dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
        "\n",
        "                # loop over the upper triangular of the distance matrix [i, j] i row j col\n",
        "                for i in range(0, D.shape[0]):\n",
        "                        for j in range(i+1, D.shape[1]):\n",
        "                                # check if the distance between any 2 centroid pairs is less than min dist or pixelese here\n",
        "                                if D[i,j] <MIN_DISTANCE:\n",
        "                                        # update our violation set with the indexes of the centroid pairs\n",
        "                                        violate.add(i)\n",
        "                                        violate.add(j)\n",
        "\n",
        "        # loop over the results\n",
        "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
        "                # extract the bounding box & centroid coordinates\n",
        "                (startX, startY, endX, endY) =bbox\n",
        "                (cX,cY) =centroid\n",
        "\n",
        "                # default annonation color is green\n",
        "                color= (0,255,0)\n",
        "\n",
        "                # if the index pair exists within the violation set then update the color RED\n",
        "                if i in violate:\n",
        "                        color= (0,0,255)\n",
        "\n",
        "                # draw a bounding box around the person & the centroid coordinates of the person\n",
        "                cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "                cv2.circle(frame, (cX, cY), 5, color, 1)\n",
        "\n",
        "\n",
        "        num_persons = len(results)\n",
        "        num_green = len(results) - len(violate)\n",
        "        num_red = len(violate)\n",
        "        frame_results.append([frame_number, num_persons, num_green, num_red])\n",
        "        frame_number += 1\n",
        "\n",
        "        text_green = \"Safe: {}\".format(num_green)\n",
        "        cv2.putText(frame, text_green, (10, frame.shape[0] - 55),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 255, 0), 3)\n",
        "\n",
        "        text_red = \"Violations: {}\".format(num_red)\n",
        "        cv2.putText(frame, text_red, (10, frame.shape[0] - 25),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
        "\n",
        "        # check to see if the output frame should be displayed to our screen\n",
        "        if screen_display:\n",
        "                cv2_imshow(frame)\n",
        "\n",
        "        # if an output video file path has been supplied & the video writer has not been initialized, do so now\n",
        "        if output_name != \"\" and writer is None:\n",
        "                # initialize video writer\n",
        "                fourcc= cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "                writer= cv2.VideoWriter(output_name, fourcc, 25, (frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "        # if the video writer is not None, write the frame to the output video file\n",
        "        if writer is not None:\n",
        "                writer.write(frame)\n",
        "\n",
        "\n",
        "# Save results in a csv file\n",
        "with open(csv_filename, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['frame', 'total_persons', 'safe', 'violations'])\n",
        "    writer.writerows(frame_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Reat CSV & Plot graph**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "75SIzZDmGop_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_csv = f'{main_path}/output/train_{run_time}.csv'\n",
        "bw_csv = f'{main_path}/output/bw_{run_time}.csv'\n",
        "\n",
        "tp_total, tn_total, fp_total, fn_total = 0, 0, 0, 0\n",
        "frame_count = 0\n",
        "\n",
        "with open(train_csv, 'r') as f_train, open(bw_csv, 'r') as f_bw:\n",
        "    train_reader = csv.DictReader(f_train)\n",
        "    bw_reader = csv.DictReader(f_bw)\n",
        "    for train_row, bw_row in zip(train_reader, bw_reader):\n",
        "        gt_safe = int(train_row['safe'])\n",
        "        gt_viol = int(train_row['violations'])\n",
        "        pred_safe = int(bw_row['safe'])\n",
        "        pred_viol = int(bw_row['violations'])\n",
        "\n",
        "        # True Positives: predicted violation, actually violation\n",
        "        tp = min(gt_viol, pred_viol)\n",
        "        # True Negatives: predicted safe, actually safe\n",
        "        tn = min(gt_safe, pred_safe)\n",
        "        # False Positives: predicted violation, actually safe\n",
        "        fp = max(0, pred_viol - gt_viol)\n",
        "        # False Negatives: predicted safe, actually violation\n",
        "        fn = max(0, pred_safe - gt_safe)\n",
        "\n",
        "        tp_total += tp\n",
        "        tn_total += tn\n",
        "        fp_total += fp\n",
        "        fn_total += fn\n",
        "        frame_count += 1\n",
        "\n",
        "# Metrics calculation\n",
        "precision = tp_total / (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0\n",
        "recall = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
        "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "tnr = tn_total / (tn_total + fp_total) if (tn_total + fp_total) > 0 else 0\n",
        "accuracy = (tp_total + tn_total) / (tp_total + tn_total + fp_total + fn_total) if (tp_total + tn_total + fp_total + fn_total) > 0 else 0\n",
        "\n",
        "print(f\"Total frames: {frame_count}\")\n",
        "print(f\"TP: {tp_total}\")\n",
        "print(f\"TN: {tn_total}\")\n",
        "print(f\"FP: {fp_total}\")\n",
        "print(f\"FN: {fn_total}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (MOU): {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(f\"TNR (True Negative Rate): {tnr:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ----------- Bar Graph -----------\n",
        "\n",
        "metrics = {\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1 Score': f1_score,\n",
        "    'TNR': tnr,\n",
        "    'Accuracy': accuracy\n",
        "}\n",
        "counts = {\n",
        "    'TP': tp_total,\n",
        "    'TN': tn_total,\n",
        "    'FP': fp_total,\n",
        "    'FN': fn_total\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.bar(metrics.keys(), metrics.values(), color='skyblue')\n",
        "plt.ylim(0, 1.05)\n",
        "plt.title('Detection Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.bar(counts.keys(), counts.values(), color='orange')\n",
        "plt.title('Counts')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.suptitle('Social Distancing Detection Report')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k9UbIPklEK-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Reverse Training**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DJ7MzPjAGlkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_csv = f'{main_path}/output/train_{run_time}.csv'\n",
        "bw_csv = f'{main_path}/output/bw_{run_time}.csv'\n",
        "\n",
        "tp_total, tn_total, fp_total, fn_total = 0, 0, 0, 0\n",
        "frame_count = 0\n",
        "\n",
        "with open(bw_csv, 'r') as f_train, open(train_csv, 'r') as f_bw:\n",
        "    train_reader = csv.DictReader(f_train)\n",
        "    bw_reader = csv.DictReader(f_bw)\n",
        "    for train_row, bw_row in zip(train_reader, bw_reader):\n",
        "        gt_safe = int(train_row['safe'])\n",
        "        gt_viol = int(train_row['violations'])\n",
        "        pred_safe = int(bw_row['safe'])\n",
        "        pred_viol = int(bw_row['violations'])\n",
        "\n",
        "        # True Positives: predicted violation, actually violation\n",
        "        tp = min(gt_viol, pred_viol)\n",
        "        # True Negatives: predicted safe, actually safe\n",
        "        tn = min(gt_safe, pred_safe)\n",
        "        # False Positives: predicted violation, actually safe\n",
        "        fp = max(0, pred_viol - gt_viol)\n",
        "        # False Negatives: predicted safe, actually violation\n",
        "        fn = max(0, pred_safe - gt_safe)\n",
        "\n",
        "        tp_total += tp\n",
        "        tn_total += tn\n",
        "        fp_total += fp\n",
        "        fn_total += fn\n",
        "        frame_count += 1\n",
        "\n",
        "# Metrics calculation\n",
        "precision = tp_total / (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0\n",
        "recall = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
        "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "tnr = tn_total / (tn_total + fp_total) if (tn_total + fp_total) > 0 else 0\n",
        "accuracy = (tp_total + tn_total) / (tp_total + tn_total + fp_total + fn_total) if (tp_total + tn_total + fp_total + fn_total) > 0 else 0\n",
        "\n",
        "print(f\"Total frames: {frame_count}\")\n",
        "print(f\"TP: {tp_total}\")\n",
        "print(f\"TN: {tn_total}\")\n",
        "print(f\"FP: {fp_total}\")\n",
        "print(f\"FN: {fn_total}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (MOU): {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(f\"TNR (True Negative Rate): {tnr:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ----------- Bar Graph -----------\n",
        "\n",
        "metrics = {\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1 Score': f1_score,\n",
        "    'TNR': tnr,\n",
        "    'Accuracy': accuracy\n",
        "}\n",
        "counts = {\n",
        "    'TP': tp_total,\n",
        "    'TN': tn_total,\n",
        "    'FP': fp_total,\n",
        "    'FN': fn_total\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.bar(metrics.keys(), metrics.values(), color='skyblue')\n",
        "plt.ylim(0, 1.05)\n",
        "plt.title('Detection Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.bar(counts.keys(), counts.values(), color='orange')\n",
        "plt.title('Counts')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.suptitle('Social Distancing Detection Report (reversed)')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "su_K6TuRGNyR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}